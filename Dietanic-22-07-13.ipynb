{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-10T19:06:43.406351Z","iopub.execute_input":"2022-07-10T19:06:43.406802Z","iopub.status.idle":"2022-07-10T19:06:43.419293Z","shell.execute_reply.started":"2022-07-10T19:06:43.406759Z","shell.execute_reply":"2022-07-10T19:06:43.418229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Contents of the Notebook:\n\n### Part1: Exploratory Data Analysis(EDA):\n1)Analysis of the features.\n\n2)Finding any relations or trends considering multiple features.\n\n### Part2: Feature Engineering and Data Cleaning:\n1)Adding any few features.\n\n2)Removing redundant features.\n\n3)Converting features into suitable form for modeling.\n\n### Part3: Predictive Modeling\n1)Running Basic Algorithms.\n\n2)Cross Validation.\n\n3)Ensembling.\n\n4)Important Features Extraction.","metadata":{}},{"cell_type":"markdown","source":"# Part1: Exploratory Data Analysis(EDA)","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('fivethirtyeight')\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:44:07.760292Z","iopub.execute_input":"2022-07-11T08:44:07.761291Z","iopub.status.idle":"2022-07-11T08:44:08.810015Z","shell.execute_reply.started":"2022-07-11T08:44:07.761183Z","shell.execute_reply":"2022-07-11T08:44:08.808900Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=pd.read_csv('/kaggle/input/titanic-machine-learning-from-disaster/train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:44:08.811796Z","iopub.execute_input":"2022-07-11T08:44:08.812145Z","iopub.status.idle":"2022-07-11T08:44:08.832088Z","shell.execute_reply.started":"2022-07-11T08:44:08.812114Z","shell.execute_reply":"2022-07-11T08:44:08.831150Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:44:08.833265Z","iopub.execute_input":"2022-07-11T08:44:08.833726Z","iopub.status.idle":"2022-07-11T08:44:08.860229Z","shell.execute_reply.started":"2022-07-11T08:44:08.833696Z","shell.execute_reply":"2022-07-11T08:44:08.859106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.isnull().sum() #널 값 확인","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:44:11.912718Z","iopub.execute_input":"2022-07-11T08:44:11.913152Z","iopub.status.idle":"2022-07-11T08:44:11.924275Z","shell.execute_reply.started":"2022-07-11T08:44:11.913113Z","shell.execute_reply":"2022-07-11T08:44:11.923372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Age, Cabin and Embarked에 널 값 확인, 나중에 값을 추가해야겠다.","metadata":{}},{"cell_type":"markdown","source":"#### How many Survived??","metadata":{}},{"cell_type":"code","source":"f,ax=plt.subplots(1,2,figsize=(18,8)) #fplt.subplots : 그래프 만들기, igsize(가로길이, 세로길이)\ndata['Survived'].value_counts().plot.pie(explode=[0,0.1],autopct='%1.1f%%', ax=ax[0],shadow=True)\nax[0].set_title('Survived')\nax[0].set_ylabel('')\nsns.countplot('Survived',data=data,ax=ax[1])\nax[1].set_title('Survived')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:44:16.919909Z","iopub.execute_input":"2022-07-11T08:44:16.920292Z","iopub.status.idle":"2022-07-11T08:44:17.268784Z","shell.execute_reply.started":"2022-07-11T08:44:16.920259Z","shell.execute_reply":"2022-07-11T08:44:17.267458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"891명 중 350명 단, 38.4%만이 살아 남았다.\n하지만, 이러한 정보만으로는 유의미한 데이터를 가졌다고 할 수 없다.\n\nAge, Embarcation, Sex등 카테고리를 이용하여, 데이터를 세분화시키자.","metadata":{}},{"cell_type":"markdown","source":"### Types Of Features","metadata":{}},{"cell_type":"markdown","source":"#### Categorical Features(범주형): \n여러가지 특성으로 분류 할 수 있다.\n\nex)Sex(남, 여), Embakred(Southampton, Liverpool)\n\n#### Ordinal Features(순서성):\nCategorical Features와 비슷하지만, 수치화 할 수 있다는 것이 특징. '상대적이다'라는 표현을 쓸 수 있는 용이성이 있다.\n\nex)높이 : 높은, 중간층, 낮음, Plcass : 1등급, 2등급, 3등\n\n#### Continous Feature(연속성):\n두 개의 값 사이에 값을 가지거나, 최댓값과, 최솟값 사이에 값들이 있다.\n\nex) 나이(100세 0세 사이의 나이들)\n\n\n","metadata":{}},{"cell_type":"markdown","source":"# Analysing The Features","metadata":{}},{"cell_type":"markdown","source":"### Sex -> Categorical Feature","metadata":{}},{"cell_type":"code","source":"data.groupby(['Sex', 'Survived'])['Survived'].count()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:44:23.419211Z","iopub.execute_input":"2022-07-11T08:44:23.419701Z","iopub.status.idle":"2022-07-11T08:44:23.431055Z","shell.execute_reply.started":"2022-07-11T08:44:23.419666Z","shell.execute_reply":"2022-07-11T08:44:23.429881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f,ax=plt.subplots(1,2,figsize=(18,8))\ndata[['Sex','Survived']].groupby(['Sex']).mean().plot.bar(ax=ax[0])\nax[0].set_title('Survived vs Sex')\nsns.countplot('Sex',hue='Survived',data=data,ax=ax[1])\nax[1].set_title('Sex:Survived vs Dead')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:44:28.176716Z","iopub.execute_input":"2022-07-11T08:44:28.177245Z","iopub.status.idle":"2022-07-11T08:44:28.505102Z","shell.execute_reply.started":"2022-07-11T08:44:28.177195Z","shell.execute_reply":"2022-07-11T08:44:28.504000Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"승선은 남자가 여자보다 훨씬 많이 했다. 하지만, '살아남은' 숫자는 2배 이상 차이난다.\n승선한 여성이 살아남은 비율은 75%, 반면에, 남성은 18%다.\n\n=> 데이터 분석할 때, 유의미한 자료가 될 것이다.","metadata":{}},{"cell_type":"markdown","source":"## Pclass -> Ordinal Feature","metadata":{}},{"cell_type":"code","source":"pd.crosstab(data.Pclass, data.Survived,margins=True).style.background_gradient(cmap='summer_r')","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:44:32.480405Z","iopub.execute_input":"2022-07-11T08:44:32.481060Z","iopub.status.idle":"2022-07-11T08:44:32.595668Z","shell.execute_reply.started":"2022-07-11T08:44:32.481021Z","shell.execute_reply":"2022-07-11T08:44:32.594525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f,ax=plt.subplots(1,2,figsize=(18,8))\ndata['Pclass'].value_counts().plot.bar(color=['#CD7F32','#FFDF00','#D3D3D3'],ax=ax[0])\nax[0].set_title('Number Of Passengers By Pclass')\nax[0].set_ylabel('Count')\nsns.countplot('Pclass', hue='Survived', data=data,ax=ax[1])\nax[1].set_title('Pclass:Survived vs Dead')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:44:35.118783Z","iopub.execute_input":"2022-07-11T08:44:35.119194Z","iopub.status.idle":"2022-07-11T08:44:35.437644Z","shell.execute_reply.started":"2022-07-11T08:44:35.119159Z","shell.execute_reply":"2022-07-11T08:44:35.436509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1등급 63%, 2등급 48%, 3등급 25% 정도만 살았다. 높은 등급일 수록 산 사람의 비율이 높아졌다.","metadata":{}},{"cell_type":"markdown","source":"성별과 좌석 등급을 같이 엮어서 보자","metadata":{}},{"cell_type":"code","source":"pd.crosstab([data.Sex, data.Survived], data.Pclass, margins=True).style.background_gradient(cmap='summer_r')","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:44:44.197376Z","iopub.execute_input":"2022-07-11T08:44:44.197742Z","iopub.status.idle":"2022-07-11T08:44:44.250698Z","shell.execute_reply.started":"2022-07-11T08:44:44.197712Z","shell.execute_reply":"2022-07-11T08:44:44.249569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.factorplot('Pclass', 'Survived', hue='Sex', data=data)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:44:46.396813Z","iopub.execute_input":"2022-07-11T08:44:46.397581Z","iopub.status.idle":"2022-07-11T08:44:46.949479Z","shell.execute_reply.started":"2022-07-11T08:44:46.397544Z","shell.execute_reply":"2022-07-11T08:44:46.948387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"FactorPlot why? 범주의 분리를 쉽게 나타낼 수 있다.\n\n단서\n1. 1등급 여성 94명 중 단, 3명만이 죽었다.\n\n2. 등급에 상관없이 여성들은 많이 살아남았고, 남자들은 많이 죽었다.","metadata":{}},{"cell_type":"markdown","source":"### Age->Continous Feature","metadata":{}},{"cell_type":"code","source":"print('Oldest Passenger was of:',data['Age'].max(),'Years')\nprint('Youngest Passenger was of:',data['Age'].min(),'Years')\nprint('Average Age on the ship:',data['Age'].mean(),'Years')","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:44:50.910687Z","iopub.execute_input":"2022-07-11T08:44:50.911874Z","iopub.status.idle":"2022-07-11T08:44:50.918938Z","shell.execute_reply.started":"2022-07-11T08:44:50.911819Z","shell.execute_reply":"2022-07-11T08:44:50.918002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f,ax=plt.subplots(1,2,figsize=(18,8))\nsns.violinplot(\"Pclass\",\"Age\", hue=\"Survived\", data=data,split=True,ax=ax[0])\nax[0].set_title('Pclass and Age vs Survived')\nax[0].set_yticks(range(0,110,10))\nsns.violinplot(\"Sex\",\"Age\", hue=\"Survived\", data=data,split=True,ax=ax[1])\nax[1].set_title('Sex and Age vs Survived')\nax[1].set_yticks(range(0,110,10))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:44:53.732458Z","iopub.execute_input":"2022-07-11T08:44:53.732858Z","iopub.status.idle":"2022-07-11T08:44:54.230349Z","shell.execute_reply.started":"2022-07-11T08:44:53.732809Z","shell.execute_reply":"2022-07-11T08:44:54.229530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"단서\n\n1. 어린이는 클래스가 높아질 수록 많다.\n2. 어린이는 클래스와 상관없이, 많이 살아남았다.\n3. 1등급 20세~50세 사람들이 가장 많이 살아남았다. 그 중, 여성들의 비율이 압도적이다.\n4. 남성들은 나이가 높을 수록, 살아남은 비율이 감소했다.","metadata":{}},{"cell_type":"markdown","source":"*나이에 널 값을 채워보자*\nhow ? 전체 나이를 평균으로 구하는 것은 양질의 데이터가 될 수가 없다. 그래서, '나이' 카테고리를 이용해보자.","metadata":{}},{"cell_type":"code","source":"data['Initial']=0\nfor i in data:\n    data['Initial']=data.Name.str.extract('([A-Za-z]+)\\.')","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:44:56.860624Z","iopub.execute_input":"2022-07-11T08:44:56.861357Z","iopub.status.idle":"2022-07-11T08:44:56.920563Z","shell.execute_reply.started":"2022-07-11T08:44:56.861315Z","shell.execute_reply":"2022-07-11T08:44:56.919346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.crosstab(data.Initial,data.Sex).T.style.background_gradient(cmap='summer_r')","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:45:01.254403Z","iopub.execute_input":"2022-07-11T08:45:01.254788Z","iopub.status.idle":"2022-07-11T08:45:01.303793Z","shell.execute_reply.started":"2022-07-11T08:45:01.254756Z","shell.execute_reply":"2022-07-11T08:45:01.303045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"'Mr' = 남성\n'Mrs', 'Ms' = 여성 and 'Mrs' = 결혼한 여성, 'Ms' = 결혼하지 않는 여성\n\n이와 같이, 카테고리를 세분화할 수록 널값에 들어갈 값의 정확성이 높아진다.","metadata":{}},{"cell_type":"code","source":"data['Initial'].replace(['Mlle','Mme','Ms','Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don'],['Miss','Miss','Miss','Mr','Mr','Mrs','Mrs','Other','Other','Other','Mr','Mr','Mr'],inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:45:05.656632Z","iopub.execute_input":"2022-07-11T08:45:05.657053Z","iopub.status.idle":"2022-07-11T08:45:05.666225Z","shell.execute_reply.started":"2022-07-11T08:45:05.657017Z","shell.execute_reply":"2022-07-11T08:45:05.665235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.groupby('Initial')['Age'].mean()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:45:07.588752Z","iopub.execute_input":"2022-07-11T08:45:07.589161Z","iopub.status.idle":"2022-07-11T08:45:07.598285Z","shell.execute_reply.started":"2022-07-11T08:45:07.589118Z","shell.execute_reply":"2022-07-11T08:45:07.597426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Filling Nan Ages","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:45:12.166751Z","iopub.execute_input":"2022-07-11T08:45:12.167147Z","iopub.status.idle":"2022-07-11T08:45:12.171697Z","shell.execute_reply.started":"2022-07-11T08:45:12.167114Z","shell.execute_reply":"2022-07-11T08:45:12.170597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.loc[(data.Age.isnull())&(data.Initial=='Mr'),'Age']=33\ndata.loc[(data.Age.isnull())&(data.Initial=='Mrs'),'Age']=36\ndata.loc[(data.Age.isnull())&(data.Initial=='Master'),'Age']=5\ndata.loc[(data.Age.isnull())&(data.Initial=='Miss'),'Age']=22\ndata.loc[(data.Age.isnull())&(data.Initial=='Other'),'Age']=46","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:45:16.748462Z","iopub.execute_input":"2022-07-11T08:45:16.748824Z","iopub.status.idle":"2022-07-11T08:45:16.764347Z","shell.execute_reply.started":"2022-07-11T08:45:16.748795Z","shell.execute_reply":"2022-07-11T08:45:16.763442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.Age.isnull().any()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:45:19.230821Z","iopub.execute_input":"2022-07-11T08:45:19.231244Z","iopub.status.idle":"2022-07-11T08:45:19.239496Z","shell.execute_reply.started":"2022-07-11T08:45:19.231207Z","shell.execute_reply":"2022-07-11T08:45:19.238364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f,ax=plt.subplots(1,2,figsize=(20,10))\ndata[data['Survived']==0].Age.plot.hist(ax=ax[0],bins=20,edgecolor='black',color='red')\nax[0].set_title('Survived= 0')\nx1=list(range(0,85,5))\nax[0].set_xticks(x1)\ndata[data['Survived']==1].Age.plot.hist(ax=ax[1],color='green',bins=20,edgecolor='black')\nax[1].set_title('Survived= 1')\nx2=list(range(0,85,5))\nax[1].set_xticks(x2)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:45:21.385701Z","iopub.execute_input":"2022-07-11T08:45:21.386091Z","iopub.status.idle":"2022-07-11T08:45:21.869103Z","shell.execute_reply.started":"2022-07-11T08:45:21.386057Z","shell.execute_reply":"2022-07-11T08:45:21.868069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"단서\n1. 5세 미만 아동은 크게 많이 살아남았다. (위급 사항시, '여성과 아동부터 살리자'라는 정책의 영향을 받았을 거라는 추측)\n\n2. 가장 나이 많은 사람도 살아남았다.\n\n3. 30대에서 40대가 가장 많이 죽었다.","metadata":{}},{"cell_type":"code","source":"sns.factorplot('Pclass','Survived',col='Initial',data=data)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:45:25.394813Z","iopub.execute_input":"2022-07-11T08:45:25.395265Z","iopub.status.idle":"2022-07-11T08:45:26.678820Z","shell.execute_reply.started":"2022-07-11T08:45:25.395229Z","shell.execute_reply":"2022-07-11T08:45:26.677586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"클래스와 상관없이 여성과 아이는 많이 살아남았다.\n\nwhy ? 여성과 아이부터 살리자는 정첵","metadata":{}},{"cell_type":"markdown","source":"### Embarked -> Categorical Value","metadata":{}},{"cell_type":"code","source":"pd.crosstab([data.Embarked,data.Pclass], [data.Sex,data.Survived],margins=True).style.background_gradient(cmap='summer_r')","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:45:30.553179Z","iopub.execute_input":"2022-07-11T08:45:30.553928Z","iopub.status.idle":"2022-07-11T08:45:30.631551Z","shell.execute_reply.started":"2022-07-11T08:45:30.553883Z","shell.execute_reply":"2022-07-11T08:45:30.630515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Chances for Survival by Port Of Embarkation","metadata":{}},{"cell_type":"code","source":"sns.factorplot('Embarked','Survived',data=data)\nfig=plt.gcf()\nfig.set_size_inches(5,3)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:45:33.740986Z","iopub.execute_input":"2022-07-11T08:45:33.742113Z","iopub.status.idle":"2022-07-11T08:45:34.089804Z","shell.execute_reply.started":"2022-07-11T08:45:33.742058Z","shell.execute_reply":"2022-07-11T08:45:34.088940Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"C항구에서 승선한 사람들이 가장 많이 살아남았고, S항구에 승선한 사람들이 가장 적게 살아남았다.","metadata":{}},{"cell_type":"code","source":"f,ax=plt.subplots(2,2,figsize=(20,15))\nsns.countplot('Embarked', data=data, ax=ax[0,0])\nax[0,0].set_title('No. Of Passengers Boarded')\nsns.countplot('Embarked', hue='Sex',data=data,ax=ax[0,1])\nax[0,1].set_title('Male-Female Split for Embarked')\nsns.countplot('Embarked', hue='Survived', data=data,ax=ax[1,0])\nax[1,0].set_title('Embarked vs Survived')\nsns.countplot('Embarked', hue='Pclass',data=data,ax=ax[1,1])\nax[1,1].set_title('Embarked vs Pclass')\nplt.subplots_adjust(wspace=0.2,hspace=0.5)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:45:37.378494Z","iopub.execute_input":"2022-07-11T08:45:37.379304Z","iopub.status.idle":"2022-07-11T08:45:37.983508Z","shell.execute_reply.started":"2022-07-11T08:45:37.379252Z","shell.execute_reply":"2022-07-11T08:45:37.982385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"단서\n\n1. S항구에서 가장 많은 사람이 승선했다. 그리고 그들의 대부분은 3등급이었다.\n\n2. C항구에서 승선한 사람들은 가장 많은 비율로 살아남았다. 추측하자면, 1등급과 2등급에 있었을 가능성이 높았기 때문이라고 추론한다.\n\n3. S항구는 부유한 사람들이 대부분이었을 것이다. 하지만, 3등급에 속한 사람들 또한 많았기 때문에 죽은 비율도 꽤 높다.\n\n4. Q항구 승선한 95% 사람들은 3등급이었다.","metadata":{"execution":{"iopub.status.busy":"2022-07-10T16:38:30.72983Z","iopub.execute_input":"2022-07-10T16:38:30.730202Z","iopub.status.idle":"2022-07-10T16:38:30.738148Z","shell.execute_reply.started":"2022-07-10T16:38:30.73016Z","shell.execute_reply":"2022-07-10T16:38:30.736609Z"}}},{"cell_type":"code","source":"sns.factorplot('Pclass', 'Survived', hue='Sex', col='Embarked', data=data)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:45:42.448644Z","iopub.execute_input":"2022-07-11T08:45:42.449054Z","iopub.status.idle":"2022-07-11T08:45:43.667910Z","shell.execute_reply.started":"2022-07-11T08:45:42.449020Z","shell.execute_reply":"2022-07-11T08:45:43.666778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"단서\n\n1. 1등급과 2등급 여성들은 거의 다 살아 남았다.\n\n2. S항구에서 승선한 3등급 사람들은 남자와 여자 상관없이 많이 죽었다. (돈 문제)\n\n3. Q항구에서 승선한 남자들이 가장 운이 없다. 그들이 가장 많이 3등급에 탑승했기 때문이다.","metadata":{}},{"cell_type":"markdown","source":"### Filling Embarked NaN\nS항구에서 승선한 사람들이 가장 많기 때문에, \"Embkared'카테고리는 'S'로 대체할 것이다.","metadata":{}},{"cell_type":"code","source":"data['Embarked'].fillna('S', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:45:47.375048Z","iopub.execute_input":"2022-07-11T08:45:47.375417Z","iopub.status.idle":"2022-07-11T08:45:47.380880Z","shell.execute_reply.started":"2022-07-11T08:45:47.375386Z","shell.execute_reply":"2022-07-11T08:45:47.380102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.Embarked.isnull().any()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:45:50.333300Z","iopub.execute_input":"2022-07-11T08:45:50.334034Z","iopub.status.idle":"2022-07-11T08:45:50.342687Z","shell.execute_reply.started":"2022-07-11T08:45:50.333991Z","shell.execute_reply":"2022-07-11T08:45:50.341450Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### SibSip -> Discrete Feature\n혼자 왔는 지, 동승했는 지 알 수 있는 지표\n\nSibling = broter, sister, stepbrother, stepsister\n\nSpouse = husband, wife","metadata":{}},{"cell_type":"code","source":"pd.crosstab([data.SibSp],data.Survived).style.background_gradient(cmap='summer_r')","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:45:53.214444Z","iopub.execute_input":"2022-07-11T08:45:53.214866Z","iopub.status.idle":"2022-07-11T08:45:53.240686Z","shell.execute_reply.started":"2022-07-11T08:45:53.214805Z","shell.execute_reply":"2022-07-11T08:45:53.239909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f,ax=plt.subplots(1,2,figsize=(20,8))\nsns.barplot('SibSp','Survived',data=data,ax=ax[0])\nax[0].set_title('SibSp vs Survived')\nsns.pointplot('SibSp','Survived',data=data,ax=ax[1]) #factorplot는 그래프가 안 나옴\nax[1].set_title('SibSp vs Survived')\nplt.close(2)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:48:03.190515Z","iopub.execute_input":"2022-07-11T08:48:03.191048Z","iopub.status.idle":"2022-07-11T08:48:03.985811Z","shell.execute_reply.started":"2022-07-11T08:48:03.191013Z","shell.execute_reply":"2022-07-11T08:48:03.984730Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.crosstab(data.SibSp,data.Pclass).style.background_gradient(cmap='summer_r')","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:48:09.886795Z","iopub.execute_input":"2022-07-11T08:48:09.887659Z","iopub.status.idle":"2022-07-11T08:48:09.918574Z","shell.execute_reply.started":"2022-07-11T08:48:09.887610Z","shell.execute_reply":"2022-07-11T08:48:09.917771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"단서\n\nSiblings 없이 혼자 탄 승객은 34.5% 확률로 살아남았다. 하지만, 그 수가 증가할 수록 생존률은 감소했다. \n\nwhy? 가족을 구하기 위해, 희생할테니깐.\n하지만, 놀랍게도 5-8명이 같이 탄 가족들은 한 명도 살아남지 못했다. 클래스의 차이 때문일까?\n\n정답이다\nSibSp>3은 모두 3등급 클래스다.","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:48:12.195206Z","iopub.execute_input":"2022-07-11T08:48:12.196237Z","iopub.status.idle":"2022-07-11T08:48:12.204372Z","shell.execute_reply.started":"2022-07-11T08:48:12.196194Z","shell.execute_reply":"2022-07-11T08:48:12.203019Z"}}},{"cell_type":"markdown","source":"# Parch","metadata":{}},{"cell_type":"code","source":"pd.crosstab(data.Parch,data.Pclass).style.background_gradient(cmap='summer_r')","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:48:32.215089Z","iopub.execute_input":"2022-07-11T08:48:32.215871Z","iopub.status.idle":"2022-07-11T08:48:32.245243Z","shell.execute_reply.started":"2022-07-11T08:48:32.215802Z","shell.execute_reply":"2022-07-11T08:48:32.244089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"가족 수가 많을 수록 3등급에 속해있다는 것을 보여준다.","metadata":{}},{"cell_type":"code","source":"f,ax=plt.subplots(1,2,figsize=(20,8))\nsns.barplot('Parch','Survived',data=data,ax=ax[0])\nax[0].set_title('Parch vs Survived')\nsns.pointplot('Parch','Survived',data=data,ax=ax[1])\nax[1].set_title('Parch vs Survived')\nplt.close(2)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:50:12.449862Z","iopub.execute_input":"2022-07-11T08:50:12.450325Z","iopub.status.idle":"2022-07-11T08:50:13.180389Z","shell.execute_reply.started":"2022-07-11T08:50:12.450283Z","shell.execute_reply":"2022-07-11T08:50:13.179114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"단서\n\n1. 가족과 같이 탄 승객들은 생존 비율이 높다. 단, 가족 수가 많을 수록 비율은 줄어들었다.\n\n2. 1-3 부모와 같이 탄 사람들은 많이 살아 남았다.\n\n3. 혼자 탑승한 것은 치명적이고, 4명 이상의 가족 또한 마찬가지다.","metadata":{}},{"cell_type":"markdown","source":"# Fare -> Continous Feature","metadata":{}},{"cell_type":"code","source":"print('Highest Fare was:',data['Fare'].max())\nprint('Lowest Fare was:',data['Fare'].min())\nprint('Average Fare was:',data['Fare'].mean())","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:50:52.032528Z","iopub.execute_input":"2022-07-11T08:50:52.032984Z","iopub.status.idle":"2022-07-11T08:50:52.041181Z","shell.execute_reply.started":"2022-07-11T08:50:52.032944Z","shell.execute_reply":"2022-07-11T08:50:52.039999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f,ax=plt.subplots(1,3,figsize=(20,8))\nsns.distplot(data[data['Pclass']==1].Fare,ax=ax[0])\nax[0].set_title('Fares in Pclass 1')\nsns.distplot(data[data['Pclass']==2].Fare,ax=ax[1])\nax[1].set_title('Fares in Pclass 2')\nsns.distplot(data[data['Pclass']==3].Fare,ax=ax[2])\nax[2].set_title('Fares in Pclass 3')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:51:07.709748Z","iopub.execute_input":"2022-07-11T08:51:07.710146Z","iopub.status.idle":"2022-07-11T08:51:08.494075Z","shell.execute_reply.started":"2022-07-11T08:51:07.710111Z","shell.execute_reply":"2022-07-11T08:51:08.492860Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"같은 등급이어도 표의 가격차이가 있다. 1등급은 가격차이가 제일 많다. 하지만, 가격은 연속적이기 때문에, 유의미한 데이터로 만들 수 있다. \n\n이제, binning을 해보자 !","metadata":{}},{"cell_type":"markdown","source":"# Observations in a Nutshell for all features:\n\nsex : 남성보다 여성이 높은 비율로 살아남았다.\n\nPclass : 1등급 사람들이 가장 많이 살아남았고, 3등급은 이와 반대된다. 그리고, 1등급, 2등급 여성들은 등급을 무시하고, 제일 많이 살아남았다.\n\nAge : 5-10 사이의 아동들이 가장 많이 살아남았으며, 15-35 사이의 사람들이 많이 죽었다.\n\nEmbarked : S항구에서 승선한 대부분 1등급 사람들 보다 C항구에서 승선한 사람들이 더 많이 살아남았따. Q항구 승객 대부분은 3등급이다.\n\nParch+SibSp : 1-2형제, 1-3와 같이 탄 사람들은 혼자 또는 이 보다 많이 동승한 사람들 보다 많이 살아남았다.","metadata":{}},{"cell_type":"markdown","source":"# Correlation Between The Features","metadata":{}},{"cell_type":"code","source":"sns.heatmap(data.corr(),annot=True,cmap='RdYlGn',linewidths=0.2) #data.corr()-->correlation matrix\nfig=plt.gcf()\nfig.set_size_inches(10,8)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-10T19:06:50.477996Z","iopub.status.idle":"2022-07-10T19:06:50.478763Z","shell.execute_reply.started":"2022-07-10T19:06:50.478556Z","shell.execute_reply":"2022-07-10T19:06:50.478576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"POSITIVE CORRELATION : B특성에서 A특성이 높아질 때, 그들은 긍정적으로 상응한다.\n\nNEGATIVE CORRELATION: B특성에서 A특성이 낮아질 때, 그들은 부정적으로 상응한다.","metadata":{}},{"cell_type":"markdown","source":"# Part2: Feature Engineering and Data Cleaning","metadata":{}},{"cell_type":"markdown","source":"필요한 정보들은 이용하고, 불필요한 정보는 삭제하자","metadata":{}},{"cell_type":"markdown","source":"### Age_band\n\ncontinous -> categorical values\n\nwhy? 유의미한 정보를 얻기 위해서\n\nex) 남자, 여자 1,0과 같은\n    나이 0~10 : 0, 10 ~20 : 1, 20~30 : 2와     같이 만들어 줄려고","metadata":{}},{"cell_type":"code","source":"data['Age_band']=0\ndata.loc[data['Age']<=16,'Age_band']=0\ndata.loc[(data['Age']>16)&(data['Age']<=32),'Age_band']=1\ndata.loc[(data['Age']>32)&(data['Age']<=48),'Age_band']=2\ndata.loc[(data['Age']>48)&(data['Age']<=64),'Age_band']=3\ndata.loc[data['Age']>64,'Age_band']=4\ndata.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:51:13.525800Z","iopub.execute_input":"2022-07-11T08:51:13.526736Z","iopub.status.idle":"2022-07-11T08:51:13.552539Z","shell.execute_reply.started":"2022-07-11T08:51:13.526680Z","shell.execute_reply":"2022-07-11T08:51:13.551498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Age_band'].value_counts().to_frame().style.background_gradient(cmap='summer')","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:51:17.615736Z","iopub.execute_input":"2022-07-11T08:51:17.616863Z","iopub.status.idle":"2022-07-11T08:51:17.632406Z","shell.execute_reply.started":"2022-07-11T08:51:17.616797Z","shell.execute_reply":"2022-07-11T08:51:17.631208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.factorplot('Age_band','Survived',data=data,col='Pclass')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:51:21.214077Z","iopub.execute_input":"2022-07-11T08:51:21.214463Z","iopub.status.idle":"2022-07-11T08:51:22.112267Z","shell.execute_reply.started":"2022-07-11T08:51:21.214431Z","shell.execute_reply":"2022-07-11T08:51:22.111049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"등급과 상관없이 나이가 많을 수록 살아남는 확률이 줄어들었다.","metadata":{}},{"cell_type":"markdown","source":"# Family_Size and Alone","metadata":{}},{"cell_type":"code","source":"data['Family_Size']=0\ndata['Family_Size']=data['Parch']+data['SibSp']#family size\ndata['Alone']=0\ndata.loc[data.Family_Size==0,'Alone']=1#Alone\n\nf,ax=plt.subplots(1,2,figsize=(18,6))\nsns.pointplot('Family_Size','Survived',data=data,ax=ax[0])\nax[0].set_title('Family_Size vs Survived')\nsns.pointplot('Alone','Survived',data=data,ax=ax[1])\nax[1].set_title('Alone vs Survived')\nplt.close(2)\nplt.close(3)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:52:24.108150Z","iopub.execute_input":"2022-07-11T08:52:24.108537Z","iopub.status.idle":"2022-07-11T08:52:24.764515Z","shell.execute_reply.started":"2022-07-11T08:52:24.108504Z","shell.execute_reply":"2022-07-11T08:52:24.763325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"혼자이거나 Familt_Size가 0이면 살아남은 확률이 굉장히 낮다. 또한, 4인 이상 가족도 마찬가지다.","metadata":{}},{"cell_type":"code","source":"sns.factorplot('Alone','Survived',data=data,hue='Sex',col='Pclass')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:52:28.838992Z","iopub.execute_input":"2022-07-11T08:52:28.839385Z","iopub.status.idle":"2022-07-11T08:52:29.932934Z","shell.execute_reply.started":"2022-07-11T08:52:28.839353Z","shell.execute_reply":"2022-07-11T08:52:29.932044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"성별과 클래스를 제외하고도 혼자 있는 것은 위험했다. \n3등급에 혼자 탑승한 여성은 가족과 동승한 사람들보다 많이 죽었다.","metadata":{}},{"cell_type":"markdown","source":"# Fare_Range","metadata":{}},{"cell_type":"markdown","source":"continous feature -> ordinal value","metadata":{}},{"cell_type":"code","source":"data['Fare_Range']=pd.qcut(data['Fare'],4)\ndata.groupby(['Fare_Range'])['Survived'].mean().to_frame().style.background_gradient(cmap='summer_r')","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:52:33.054833Z","iopub.execute_input":"2022-07-11T08:52:33.055274Z","iopub.status.idle":"2022-07-11T08:52:33.088082Z","shell.execute_reply.started":"2022-07-11T08:52:33.055239Z","shell.execute_reply":"2022-07-11T08:52:33.087230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"금액이 비쌀수록, 살아남은 확률도 높아졌다. \n유의미한 숫자로 바꿔보자.","metadata":{}},{"cell_type":"code","source":"data['Fare_cat']=0\ndata.loc[data['Fare']<=7.91,'Fare_cat']=0\ndata.loc[(data['Fare']>7.91)&(data['Fare']<=14.454),'Fare_cat']=1\ndata.loc[(data['Fare']>14.454)&(data['Fare']<=31),'Fare_cat']=2\ndata.loc[(data['Fare']>31)&(data['Fare']<=513),'Fare_cat']=3","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:52:35.399278Z","iopub.execute_input":"2022-07-11T08:52:35.399786Z","iopub.status.idle":"2022-07-11T08:52:35.415430Z","shell.execute_reply.started":"2022-07-11T08:52:35.399740Z","shell.execute_reply":"2022-07-11T08:52:35.414193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.factorplot('Fare_cat','Survived',data=data,hue='Sex')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:52:37.389100Z","iopub.execute_input":"2022-07-11T08:52:37.389491Z","iopub.status.idle":"2022-07-11T08:52:38.018178Z","shell.execute_reply.started":"2022-07-11T08:52:37.389453Z","shell.execute_reply":"2022-07-11T08:52:38.017233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"임금이 높을 수록 살아남은 확률이 높다는 것을 입증했다. \n\n나중에, Modeling을 할 때, 성별과 관련시킨다면 시너지를 발휘할 수 있다. ","metadata":{}},{"cell_type":"markdown","source":"# Converting String Values into Numeric","metadata":{}},{"cell_type":"code","source":"data['Sex'].replace(['male','female'],[0,1],inplace=True)\ndata['Embarked'].replace(['S','C','Q'],[0,1,2],inplace=True)\ndata['Initial'].replace(['Mr','Mrs','Miss','Master','Other'],[0,1,2,3,4],inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:52:40.783395Z","iopub.execute_input":"2022-07-11T08:52:40.783921Z","iopub.status.idle":"2022-07-11T08:52:40.799087Z","shell.execute_reply.started":"2022-07-11T08:52:40.783872Z","shell.execute_reply":"2022-07-11T08:52:40.797753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dropping UnNeeded Features\n\nName : 철수, 영희 이름이 죽음에 연관이 있지 않다.\n\nAge : Age_band할 때 사용했기 때문에, 더이상 필요없다.\n\nTicket : 무작위 문자열이라 필요없다.\n\nFare : Fare_cat할 때 사용했기 때문에, 더이상 필요없다.\n\nCabin : 널값들이 많고, 많은 사람들이 2개이상 이용했다. 그래서 객관적인 지표로 쓰기에는 무리가 있다.\n\nFare_Range : Fare_cat 특성을 만들었기 때문에, 필요없다.\n\nPassengerld : 카테고리화 할 수 없다.\n","metadata":{}},{"cell_type":"code","source":"data.drop(['Name','Age','Ticket','Fare','Cabin','Fare_Range','PassengerId'],axis=1,inplace=True)\nsns.heatmap(data.corr(),annot=True,cmap='RdYlGn',linewidths=0.2,annot_kws={'size':20})\nfig=plt.gcf()\nfig.set_size_inches(18,15)\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:52:44.557073Z","iopub.execute_input":"2022-07-11T08:52:44.557471Z","iopub.status.idle":"2022-07-11T08:52:45.561560Z","shell.execute_reply.started":"2022-07-11T08:52:44.557439Z","shell.execute_reply":"2022-07-11T08:52:45.560540Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Part3:Predictive Modeling","metadata":{}},{"cell_type":"markdown","source":"위와 같은 작업을 했지만, test_case를 넣었을 때, 그들이 살았을지 죽었을지 정확하게 판단할 수 없다. 이를 더 정확하게 하기 위해서는 알고리즘을 이용해야 한다.","metadata":{}},{"cell_type":"markdown","source":"\n\n1) Logistic Regression\n\n2) Support Vector Machines(Linear and radial)\n\n3) Random Forest\n\n4) K-Nearest Neighbours\n\n5) Naive Bayes\n\n6) Decision Tree\n\n7) Logistic Regression","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn import svm\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split #train_test_split오류, pip install sklearn","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:55:14.004497Z","iopub.execute_input":"2022-07-11T08:55:14.004932Z","iopub.status.idle":"2022-07-11T08:55:14.011933Z","shell.execute_reply.started":"2022-07-11T08:55:14.004894Z","shell.execute_reply":"2022-07-11T08:55:14.010792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train,test=train_test_split(data,test_size=0.3,random_state=0,stratify=data['Survived'])\ntrain_X=train[train.columns[1:]]\ntrain_Y=train[train.columns[:1]]\ntest_X=test[test.columns[1:]]\ntest_Y=test[test.columns[:1]]\nX=data[data.columns[1:]]\nY=data['Survived']","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:55:19.650411Z","iopub.execute_input":"2022-07-11T08:55:19.650778Z","iopub.status.idle":"2022-07-11T08:55:19.663925Z","shell.execute_reply.started":"2022-07-11T08:55:19.650749Z","shell.execute_reply":"2022-07-11T08:55:19.662762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Radial Support Vectop Machines(rbf-SVM)","metadata":{}},{"cell_type":"code","source":"model=svm.SVC(kernel='rbf',C=1,gamma=0.1)\nmodel.fit(train_X,train_Y)\nprediction1=model.predict(test_X)\nprint('Accuracy for rbf SVM is ',metrics.accuracy_score(prediction1,test_Y))","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:55:22.365348Z","iopub.execute_input":"2022-07-11T08:55:22.365728Z","iopub.status.idle":"2022-07-11T08:55:22.400736Z","shell.execute_reply.started":"2022-07-11T08:55:22.365697Z","shell.execute_reply":"2022-07-11T08:55:22.399560Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Linear Support Vector Machine(linear-SVM)","metadata":{}},{"cell_type":"code","source":"model=svm.SVC(kernel='linear',C=0.1,gamma=0.1)\nmodel.fit(train_X,train_Y)\nprediction2=model.predict(test_X)\nprint('Accuracy for linear SVM is',metrics.accuracy_score(prediction2,test_Y))","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:55:24.608142Z","iopub.execute_input":"2022-07-11T08:55:24.608703Z","iopub.status.idle":"2022-07-11T08:55:24.633584Z","shell.execute_reply.started":"2022-07-11T08:55:24.608659Z","shell.execute_reply":"2022-07-11T08:55:24.632577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Logistic Regression","metadata":{}},{"cell_type":"code","source":"model = LogisticRegression()\nmodel.fit(train_X,train_Y)\nprediction3=model.predict(test_X)\nprint('The accuracy of the Logistic Regression is',metrics.accuracy_score(prediction3,test_Y))","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:55:27.033444Z","iopub.execute_input":"2022-07-11T08:55:27.034245Z","iopub.status.idle":"2022-07-11T08:55:27.056689Z","shell.execute_reply.started":"2022-07-11T08:55:27.034201Z","shell.execute_reply":"2022-07-11T08:55:27.055361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Decision Tree","metadata":{}},{"cell_type":"code","source":"model=DecisionTreeClassifier()\nmodel.fit(train_X,train_Y)\nprediction4=model.predict(test_X)\nprint('The accuracy of the Decision Tree is',metrics.accuracy_score(prediction4,test_Y))","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:55:29.045634Z","iopub.execute_input":"2022-07-11T08:55:29.046043Z","iopub.status.idle":"2022-07-11T08:55:29.060545Z","shell.execute_reply.started":"2022-07-11T08:55:29.046000Z","shell.execute_reply":"2022-07-11T08:55:29.059693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# K-Nearest Neighbours(KNN)","metadata":{}},{"cell_type":"code","source":"model=KNeighborsClassifier() \nmodel.fit(train_X,train_Y)\nprediction5=model.predict(test_X)\nprint('The accuracy of the KNN is',metrics.accuracy_score(prediction5,test_Y))","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:55:31.037408Z","iopub.execute_input":"2022-07-11T08:55:31.037779Z","iopub.status.idle":"2022-07-11T08:55:31.063741Z","shell.execute_reply.started":"2022-07-11T08:55:31.037747Z","shell.execute_reply":"2022-07-11T08:55:31.062572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"값을 정확하게 하기위해, 이웃들을 5명으로 설정하겠다.","metadata":{}},{"cell_type":"code","source":"a_index=list(range(1,11))\na=pd.Series()\nx=[0,1,2,3,4,5,6,7,8,9,10]\nfor i in list(range(1,11)):\n    model=KNeighborsClassifier(n_neighbors=i) \n    model.fit(train_X,train_Y)\n    prediction=model.predict(test_X)\n    a=a.append(pd.Series(metrics.accuracy_score(prediction,test_Y)))\nplt.plot(a_index, a)\nplt.xticks(x)\nfig=plt.gcf()\nfig.set_size_inches(12,6)\nplt.show()\nprint('Accuracies for different values of n are:',a.values,'with the max value as ',a.values.max())","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:55:32.895599Z","iopub.execute_input":"2022-07-11T08:55:32.895988Z","iopub.status.idle":"2022-07-11T08:55:33.297727Z","shell.execute_reply.started":"2022-07-11T08:55:32.895955Z","shell.execute_reply":"2022-07-11T08:55:33.296626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Gaussian Naive Bayes","metadata":{}},{"cell_type":"code","source":"model=GaussianNB()\nmodel.fit(train_X,train_Y)\nprediction6=model.predict(test_X)\nprint('The accuracy of the NaiveBayes is',metrics.accuracy_score(prediction6,test_Y))","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:55:36.027476Z","iopub.execute_input":"2022-07-11T08:55:36.027887Z","iopub.status.idle":"2022-07-11T08:55:36.040907Z","shell.execute_reply.started":"2022-07-11T08:55:36.027837Z","shell.execute_reply":"2022-07-11T08:55:36.039429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Random Forests","metadata":{}},{"cell_type":"code","source":"model=RandomForestClassifier(n_estimators=100)\nmodel.fit(train_X,train_Y)\nprediction7=model.predict(test_X)\nprint('The accuracy of the Random Forests is',metrics.accuracy_score(prediction7,test_Y))","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:55:38.315131Z","iopub.execute_input":"2022-07-11T08:55:38.315497Z","iopub.status.idle":"2022-07-11T08:55:38.543523Z","shell.execute_reply.started":"2022-07-11T08:55:38.315467Z","shell.execute_reply":"2022-07-11T08:55:38.542382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"알고르즘 확률은 90%이상은 넘어가야 정확하다고 판단한다. 하지만, 다른 케이스를 넣을 때 마다, 확률이 변동될 수가 있다. \n\n이를 해결하기 위해서, 여러번의 테스트가 필요하다. 다양한 케이스들을 넣어 시도를 하고, 정확성을 높이자.","metadata":{}},{"cell_type":"markdown","source":"# Cross Validation","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import KFold \nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:55:54.565369Z","iopub.execute_input":"2022-07-11T08:55:54.565780Z","iopub.status.idle":"2022-07-11T08:55:54.570737Z","shell.execute_reply.started":"2022-07-11T08:55:54.565744Z","shell.execute_reply":"2022-07-11T08:55:54.569413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kfold = KFold(n_splits=10, shuffle=True, random_state=22) #랜덤의 여지가 없는데 랜덤하게 하라고 명령한 것. so 'shuffle=True'를 삽입\nxyz=[]\naccuracy=[]\nstd=[]\nclassifiers=['Linear Svm','Radial Svm','Logistic Regression','KNN','Decision Tree','Naive Bayes','Random Forest']\nmodels=[svm.SVC(kernel='linear'),svm.SVC(kernel='rbf'),LogisticRegression(),KNeighborsClassifier(n_neighbors=9),DecisionTreeClassifier(),GaussianNB(),RandomForestClassifier(n_estimators=100)]\nfor i in models:\n    model = i\n    cv_result = cross_val_score(model,X,Y, cv = kfold,scoring = \"accuracy\")\n    cv_result=cv_result\n    xyz.append(cv_result.mean())\n    std.append(cv_result.std())\n    accuracy.append(cv_result)\nnew_models_dataframe2=pd.DataFrame({'CV Mean':xyz,'Std':std},index=classifiers)       \nnew_models_dataframe2","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:55:58.539690Z","iopub.execute_input":"2022-07-11T08:55:58.540104Z","iopub.status.idle":"2022-07-11T08:56:01.755269Z","shell.execute_reply.started":"2022-07-11T08:55:58.540068Z","shell.execute_reply":"2022-07-11T08:56:01.754224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.subplots(figsize=(12,6))\nbox=pd.DataFrame(accuracy,index=[classifiers])\nbox.T.boxplot()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:56:03.831912Z","iopub.execute_input":"2022-07-11T08:56:03.832985Z","iopub.status.idle":"2022-07-11T08:56:04.100955Z","shell.execute_reply.started":"2022-07-11T08:56:03.832946Z","shell.execute_reply":"2022-07-11T08:56:04.099946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_models_dataframe2['CV Mean'].plot.barh(width=0.8)\nplt.title('Average CV Mean Accuracy')\nfig=plt.gcf()\nfig.set_size_inches(8,5)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:56:06.982080Z","iopub.execute_input":"2022-07-11T08:56:06.982556Z","iopub.status.idle":"2022-07-11T08:56:07.201944Z","shell.execute_reply.started":"2022-07-11T08:56:06.982478Z","shell.execute_reply":"2022-07-11T08:56:07.200782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"불균형으로 인해, 분류 정확성을 잘못 도출할 수 있다. 그래서 이러한 혼란을 막기 위해 'confusion matrix'를 사용할 것이다. \n\n이는, 어디서 모델이 잘못되었는가? 어떤 class에서 잘못되었는 가를 말해준다.","metadata":{}},{"cell_type":"markdown","source":"# Confusion Matrix\nclassifier로 만들어진 요소중에 잘 된 분류와 잘 되지 않은 분류의 수를 알려준다.","metadata":{}},{"cell_type":"code","source":"f,ax=plt.subplots(3,3,figsize=(12,10))\ny_pred = cross_val_predict(svm.SVC(kernel='rbf'),X,Y,cv=10)\nsns.heatmap(confusion_matrix(Y,y_pred),ax=ax[0,0],annot=True,fmt='2.0f')\nax[0,0].set_title('Matrix for rbf-SVM')\ny_pred = cross_val_predict(svm.SVC(kernel='linear'),X,Y,cv=10)\nsns.heatmap(confusion_matrix(Y,y_pred),ax=ax[0,1],annot=True,fmt='2.0f')\nax[0,1].set_title('Matrix for Linear-SVM')\ny_pred = cross_val_predict(KNeighborsClassifier(n_neighbors=9),X,Y,cv=10)\nsns.heatmap(confusion_matrix(Y,y_pred),ax=ax[0,2],annot=True,fmt='2.0f')\nax[0,2].set_title('Matrix for KNN')\ny_pred = cross_val_predict(RandomForestClassifier(n_estimators=100),X,Y,cv=10)\nsns.heatmap(confusion_matrix(Y,y_pred),ax=ax[1,0],annot=True,fmt='2.0f')\nax[1,0].set_title('Matrix for Random-Forests')\ny_pred = cross_val_predict(LogisticRegression(),X,Y,cv=10)\nsns.heatmap(confusion_matrix(Y,y_pred),ax=ax[1,1],annot=True,fmt='2.0f')\nax[1,1].set_title('Matrix for Logistic Regression')\ny_pred = cross_val_predict(DecisionTreeClassifier(),X,Y,cv=10)\nsns.heatmap(confusion_matrix(Y,y_pred),ax=ax[1,2],annot=True,fmt='2.0f')\nax[1,2].set_title('Matrix for Decision Tree')\ny_pred = cross_val_predict(GaussianNB(),X,Y,cv=10)\nsns.heatmap(confusion_matrix(Y,y_pred),ax=ax[2,0],annot=True,fmt='2.0f')\nax[2,0].set_title('Matrix for Naive Bayes')\nplt.subplots_adjust(hspace=0.2,wspace=0.2)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:56:11.542505Z","iopub.execute_input":"2022-07-11T08:56:11.542986Z","iopub.status.idle":"2022-07-11T08:56:17.267550Z","shell.execute_reply.started":"2022-07-11T08:56:11.542944Z","shell.execute_reply":"2022-07-11T08:56:17.266354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"왼쪽은 정확한 예측을 보여준다. 반면에, 오른쪽은 잘못된 예그측을 보여준다.\n\nSVM : 정확한 예측 : 491명은 죽고, 247명은 살았다. CV정확성은 (491+247)/891 = 82.8%\n    : 잘못된 예측 : 58명은 살았지만 죽은 사람으로 분류, 95명은 죽었지만 산사람으로 분류\n\n결론적으로는, SVM은 죽은 사람을 예측하는 데 정확성이 높았으며, NaiveBayes는 산 사람을 예측하는 데 정확성이 높았다.","metadata":{}},{"cell_type":"markdown","source":"# Hyper=parameters Tuning\n\nSvm은 C 그리고 gamma라는 매개변수가 있다.\n유사하지만 다른 매개변수를 'Hyper-parameters'라고 한다. \n\n우리는 이를 조정하고 변화시켜 기계를 학습시킨다면, 더 높은 modeling을 할 수 있다.","metadata":{}},{"cell_type":"markdown","source":"### svm","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nC=[0.05,0.1,0.2,0.3,0.25,0.4,0.5,0.6,0.7,0.8,0.9,1]\ngamma=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\nkernel=['rbf','linear']\nhyper={'kernel':kernel,'C':C,'gamma':gamma}\ngd=GridSearchCV(estimator=svm.SVC(),param_grid=hyper,verbose=True)\ngd.fit(X,Y)\nprint(gd.best_score_)\nprint(gd.best_estimator_)","metadata":{"execution":{"iopub.status.busy":"2022-07-11T08:56:22.317488Z","iopub.execute_input":"2022-07-11T08:56:22.318495Z","iopub.status.idle":"2022-07-11T08:56:52.248576Z","shell.execute_reply.started":"2022-07-11T08:56:22.318449Z","shell.execute_reply":"2022-07-11T08:56:52.247363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Random Forests","metadata":{}},{"cell_type":"code","source":"n_estimators=range(100,1000,100)\nhyper={'n_estimators':n_estimators}\ngd=GridSearchCV(estimator=RandomForestClassifier(random_state=0),param_grid=hyper,verbose=True)\ngd.fit(X,Y)\nprint(gd.best_score_)\nprint(gd.best_estimator_)","metadata":{"execution":{"iopub.status.busy":"2022-07-11T09:00:04.741758Z","iopub.execute_input":"2022-07-11T09:00:04.742063Z","iopub.status.idle":"2022-07-11T09:00:52.937571Z","shell.execute_reply.started":"2022-07-11T09:00:04.742034Z","shell.execute_reply":"2022-07-11T09:00:52.936483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ensembling\n\n정확성을 높이기 위한 작업이다. \n다양한 model을 합쳐서 하나의 model로 만드는 것이다.\n\n방법\n1. Voting Classifier\n2. Bagging\n3. Boosting","metadata":{}},{"cell_type":"markdown","source":"# Voting Classifier\n\n결합된 예측을 합치는 데 가장 간단한 방법이다.\n모든 submodel들의 예측을 기반한 결과의 평균을 준다.\n\n그리고, submodel과 basemodel은 모든 다른 type이다","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\nensemble_lin_rbf=VotingClassifier(estimators=[('KNN',KNeighborsClassifier(n_neighbors=10)),\n                                              ('RBF',svm.SVC(probability=True,kernel='rbf',C=0.5,gamma=0.1)),\n                                              ('RFor',RandomForestClassifier(n_estimators=500,random_state=0)),\n                                              ('LR',LogisticRegression(C=0.05)),\n                                              ('DT',DecisionTreeClassifier(random_state=0)),\n                                              ('NB',GaussianNB()),\n                                              ('svm',svm.SVC(kernel='linear',probability=True))\n                                             ], \n                       voting='soft').fit(train_X,train_Y)\nprint('The accuracy for ensembled model is:',ensemble_lin_rbf.score(test_X,test_Y))\ncross=cross_val_score(ensemble_lin_rbf,X,Y, cv = 10,scoring = \"accuracy\")\nprint('The cross validated score is',cross.mean())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Bagging\n\n앙상블 학습. 배깅은 샘플을 여러 번 뽑아(Bootstrap) 각 모델을 학습시켜 결과물을 집계(Aggregration)하는 방법입니다.\n\n최종은 투표 방식으로 한다. 전체 모델에서 예측한 값 중 가장 많은 값을 최종 예측값으로 선정한다는 것입니다.\n6개의 결정 트리 모델이 있다고 합시다. \n\n4개는 A로 예측했고, 2개는 B로 예측했다면 투표에 의해 4개의 모델이 선택한 A를 최종 결과로 예측한다는 것입니다.\n\nex) sample1, sample2, sample3, sample4 등을 학습시킨 후 결과물을 본다.","metadata":{}},{"cell_type":"markdown","source":"#### Bagged KNN\n\n배깅은 분산이 잘 나타나는 곳에서 잘 작동한다. 예로, Decision Tree 또는 Random Forests에서 작동한다. 우리는 KNN에서도 구동할 수 있다.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import BaggingClassifier\nmodel=BaggingClassifier(base_estimator=KNeighborsClassifier(n_neighbors=3),random_state=0,n_estimators=700)\nmodel.fit(train_X,train_Y)\nprediction=model.predict(test_X)\nprint('The accuracy for bagged KNN is:',metrics.accuracy_score(prediction,test_Y))\nresult=cross_val_score(model,X,Y,cv=10,scoring='accuracy')\nprint('The cross validated score for bagged KNN is:',result.mean())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Bagged DecisionTree","metadata":{}},{"cell_type":"code","source":"model=BaggingClassifier(base_estimator=DecisionTreeClassifier(),random_state=0,n_estimators=100)\nmodel.fit(train_X,train_Y)\nprediction=model.predict(test_X)\nprint('The accuracy for bagged Decision Tree is:',metrics.accuracy_score(prediction,test_Y))\nresult=cross_val_score(model,X,Y,cv=10,scoring='accuracy')\nprint('The cross validated score for bagged Decision Tree is:',result.mean())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Boosting\n머신러닝 앙상블 기법 중 하나이다. 연속적으로 weak learner들을 여러 개 결합하여 예측 혹은 분류 성능을 높이는 알고리즘이다.\n\n약한 분류기가 순차적으로 학습하며, 앞에서 학습한 분류기가 예측이 틀린 데이터에 대해 다음 분류기가 가중치를 인가해서 학습을 이어 진행하는 방식","metadata":{}},{"cell_type":"markdown","source":"#### AdaBoost(Adaptive Boosting)\n\nDecesion Tree을 통해 분류 기준으로 분류 된다. 단, 이는 다른 알고리즘으로 대체가능하다.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nada=AdaBoostClassifier(n_estimators=200,random_state=0,learning_rate=0.1)\nresult=cross_val_score(ada,X,Y,cv=10,scoring='accuracy')\nprint('The cross validated score for AdaBoost is:',result.mean())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Stochastic Gradient Bossting\n여기서도 Decision Tree로 weak learner들을 분류한다.","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\ngrad=GradientBoostingClassifier(n_estimators=500,random_state=0,learning_rate=0.1)\nresult=cross_val_score(grad,X,Y,cv=10,scoring='accuracy')\nprint('The cross validated score for Gradient Boosting is:',result.mean())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### XGBoost","metadata":{}},{"cell_type":"code","source":"import xgboost as xg\nxgboost=xg.XGBClassifier(n_estimators=900,learning_rate=0.1)\nresult=cross_val_score(xgboost,X,Y,cv=10,scoring='accuracy')\nprint('The cross validated score for XGBoost is:',result.mean())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"AdaBoost일 때, 정확성이 가장 높았다. 이제 우리는 Hyper_Parameter Tuning을 통해 이 정확성을 더욱 높이겠다.","metadata":{}},{"cell_type":"markdown","source":"#### Hyper-Parameter Tuning for AdaBoos","metadata":{}},{"cell_type":"code","source":"n_estimators=list(range(100,1100,100))\nlearn_rate=[0.05,0.1,0.2,0.3,0.25,0.4,0.5,0.6,0.7,0.8,0.9,1]\nhyper={'n_estimators':n_estimators,'learning_rate':learn_rate}\ngd=GridSearchCV(estimator=AdaBoostClassifier(),param_grid=hyper,verbose=True)\ngd.fit(X,Y)\nprint(gd.best_score_)\nprint(gd.best_estimator_)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"우리가 가질 수 있는 Adaboost의 가장 높은 정확성은 83.16%다. n_extimators = 이고, learning_rate= 이다.","metadata":{}},{"cell_type":"markdown","source":"#### Confusion Matrix for the Best Model","metadata":{}},{"cell_type":"code","source":"ada=AdaBoostClassifier(n_estimators=200,random_state=0,learning_rate=0.05)\nresult=cross_val_predict(ada,X,Y,cv=10)\nsns.heatmap(confusion_matrix(Y,result),cmap='winter',annot=True,fmt='2.0f')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Importance","metadata":{}},{"cell_type":"code","source":"f,ax=plt.subplots(2,2,figsize=(15,12))\nmodel=RandomForestClassifier(n_estimators=500,random_state=0)\nmodel.fit(X,Y)\npd.Series(model.feature_importances_,X.columns).sort_values(ascending=True).plot.barh(width=0.8,ax=ax[0,0])\nax[0,0].set_title('Feature Importance in Random Forests')\nmodel=AdaBoostClassifier(n_estimators=200,learning_rate=0.05,random_state=0)\nmodel.fit(X,Y)\npd.Series(model.feature_importances_,X.columns).sort_values(ascending=True).plot.barh(width=0.8,ax=ax[0,1],color='#ddff11')\nax[0,1].set_title('Feature Importance in AdaBoost')\nmodel=GradientBoostingClassifier(n_estimators=500,learning_rate=0.1,random_state=0)\nmodel.fit(X,Y)\npd.Series(model.feature_importances_,X.columns).sort_values(ascending=True).plot.barh(width=0.8,ax=ax[1,0],cmap='RdYlGn_r')\nax[1,0].set_title('Feature Importance in Gradient Boosting')\nmodel=xg.XGBClassifier(n_estimators=900,learning_rate=0.1)\nmodel.fit(X,Y)\npd.Series(model.feature_importances_,X.columns).sort_values(ascending=True).plot.barh(width=0.8,ax=ax[1,1],color='#FD0F00')\nax[1,1].set_title('Feature Importance in XgBoost')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"RandomForests와 AdaBoost와 같은 다양한 중요한 특징을 볼 수 있다.","metadata":{}},{"cell_type":"markdown","source":"관측\n\n1. Initial, Fare_cat, Pclass, Family_Size 특성이 주요했다.\n\n2. 성별은 Decesion Tree에서만 두각을 들어내고 다른 곳에서는 주요했지 않았지만, 클래스와 연관시켰을 땐, 주요했다.\n\n3. Pclass 및 Fare_cat은 혼자, Parch 및 Sibsp와 함께 승객 및 Family_Size의 상태를 나타난다.","metadata":{}}]}